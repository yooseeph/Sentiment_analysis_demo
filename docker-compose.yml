version: "3.8"

services:
  app:
    build:
      context: .
    container_name: sentiment_analysis
    # Make sure your Dockerfile has: EXPOSE 7861
    ports:
      - "7877:7877"
    env_file:
      - .env
    environment:
      # Ensure the app listens on the same port we expose/map
      SERVER_PORT: "7877"
      # Use local VAD model path
      VAD_MODEL_PATH: "models/vad/simple-vad"
      # Prevent tzdata prompts during build/run (optional but safe)
      TZ: "Etc/UTC"
    volumes:
      # Mount local folders into the container
      - ./models:/app/models:ro  # Contains transcription, VAD, and other models
      - ./logs:/app/logs
      - ./GradioTEMP:/app/GradioTEMP
      # Cache directory for downloaded models (optional, for faster rebuilds)
      - $HOME/.cache/torch:/root/.cache/torch:ro
    # --- GPU (optional) ---
    # Uncomment this block if you want GPU in Docker Desktop (WSL2) and have NVIDIA runtime:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: ["gpu"]
    #           count: "all"
    #           driver: "nvidia"
    # Alternatively (Compose v2 supports this):
    # gpus: "all"
